{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgokcin/bag-of-features/blob/master/bof-google-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVE_5hrjYytc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a0bb3e2d-2f19-4907-e1d3-901924314db2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z361Gh7lcuu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "107af04f-f7aa-45dd-8e45-529195da5fad"
      },
      "source": [
        "!pip uninstall opencv-python -y\n",
        "# downgrade OpenCV a bit since some none-free features are not avilable\n",
        "!pip install opencv-contrib-python==3.4.2.17 --force-reinstall"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling opencv-python-4.1.2.30:\n",
            "  Successfully uninstalled opencv-python-4.1.2.30\n",
            "Collecting opencv-contrib-python==3.4.2.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/29/fc60b2de1713aa92946992544329f20ccb5e4ba26290f403e04b7da44105/opencv_contrib_python-3.4.2.17-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6MB 102kB/s \n",
            "\u001b[?25hCollecting numpy>=1.11.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 102kB/s \n",
            "\u001b[31mERROR: imgaug 0.2.9 requires opencv-python, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: dopamine-rl 1.0.5 requires opencv-python>=3.4.1.15, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 requires opencv-python, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, opencv-contrib-python\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed numpy-1.18.4 opencv-contrib-python-3.4.2.17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbyoFW-XYtpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbaKbo_dbZGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFiles(train, path):\n",
        "    images = []\n",
        "    count = 0\n",
        "    for folder in os.listdir(path):\n",
        "        for file in os.listdir(os.path.join(path, folder)):\n",
        "            images.append(os.path.join(path, os.path.join(folder, file)))\n",
        "\n",
        "    # if (train is True):\n",
        "    #     np.random.shuffle(images)\n",
        "\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEmTyjSdbgXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_keypoints(img, kp):\n",
        "    keypoints = cv2.drawKeypoints(img, kp, outImage=None)\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.imshow(keypoints)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uLFgFglbi2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDescriptors(sift, img, feature_extraction):\n",
        "    if feature_extraction == 'kp':\n",
        "        kp, des = sift.detectAndCompute(img, None)\n",
        "        # draw_keypoints(img, kp)\n",
        "        return des\n",
        "    if feature_extraction == 'grid':\n",
        "        step_size = 15\n",
        "        kp = [cv2.KeyPoint(x, y, step_size) for y in\n",
        "              range(0, img.shape[0], step_size)\n",
        "              for x in range(0, img.shape[1], step_size)]\n",
        "\n",
        "        kp, des = sift.compute(img, kp)\n",
        "        # draw_keypoints(img, kp)\n",
        "\n",
        "        return des\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-58xW6NbmPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readImage(img_path):\n",
        "    img = cv2.imread(img_path, 0)\n",
        "    # return cv2.resize(img, (150, 150))\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFz7tHmHbn7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vstackDescriptors(descriptor_list):\n",
        "    descriptors = np.array(descriptor_list[0])\n",
        "    for descriptor in descriptor_list[1:]:\n",
        "        descriptors = np.vstack((descriptors, descriptor))\n",
        "\n",
        "    return descriptors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDVa0j6hbqP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusterDescriptors(descriptors, no_clusters, alg):\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    descriptors_normalized = scaler.fit_transform(descriptors)\n",
        "\n",
        "    if alg == 'kmeans':\n",
        "        kmeans = KMeans(n_clusters=no_clusters).fit(descriptors_normalized)\n",
        "        return kmeans\n",
        "    elif alg == 'meanshift':\n",
        "\n",
        "        bandwidth = estimate_bandwidth(descriptors_normalized, quantile=.002,\n",
        "                                       n_samples=30000)\n",
        "\n",
        "        ms = MeanShift(bandwidth=bandwidth, n_jobs=-1, bin_seeding=True,\n",
        "                       cluster_all=False)\n",
        "        # ms = MeanShift(bandwidth=bandwidth, n_jobs=-1, bin_seeding=True)\n",
        "        ms.fit(descriptors_normalized)\n",
        "        labels = ms.labels_\n",
        "        cluster_centers = ms.cluster_centers_\n",
        "        print(bandwidth)\n",
        "        # print(cluster_centers)\n",
        "\n",
        "        labels_unique = np.unique(labels)\n",
        "        n_clusters_ = len(labels_unique)\n",
        "\n",
        "        print(\"number of estimated clusters : %d\" % n_clusters_)\n",
        "\n",
        "        return ms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4nUpUyHbtFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractFeatures(cluster, descriptor_list, image_count, no_clusters):\n",
        "    histogram = np.array([np.zeros(len(cluster.cluster_centers_)) for i in\n",
        "                            range(image_count)])\n",
        "    for i in range(image_count):\n",
        "        for j in range(len(descriptor_list[i])):\n",
        "            feature = descriptor_list[i][j]\n",
        "            feature = feature.reshape(1, 128)\n",
        "            # nearest neigh.\n",
        "            idx = cluster.predict(feature)\n",
        "            histogram[i][idx] += 1\n",
        "\n",
        "    return histogram\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5NxDHgMbvt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeFeatures(scale, features):\n",
        "    return scale.transform(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM3hGCiXbxzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotHistogram(im_features, no_clusters):\n",
        "    x_scalar = np.arange(no_clusters)\n",
        "    y_scalar = np.array(\n",
        "        [abs(np.sum(im_features[:, h], dtype=np.int32)) for h in\n",
        "         range(no_clusters)])\n",
        "\n",
        "    plt.bar(x_scalar, y_scalar)\n",
        "    plt.xlabel(\"Visual Word Index\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Complete Vocabulary Generated\")\n",
        "    # plt.xticks(x_scalar + 0.4, x_scalar)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP1O0EFqbzd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotConfusionMatrix(y_true, y_pred, classes,\n",
        "                        normalize=False,\n",
        "                        title=None,\n",
        "                        cmap=plt.cm.Blues):\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O51NBaXwb2NC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotConfusions(true, predictions):\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    class_names = [\"airplanes\", \"cars\", \"faces\", \"motorbikes\"]\n",
        "    plotConfusionMatrix(true, predictions, classes=class_names,\n",
        "                        title='Confusion matrix, without normalization')\n",
        "\n",
        "    plotConfusionMatrix(true, predictions, classes=class_names, normalize=True,\n",
        "                        title='Normalized confusion matrix')\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFp_vZ6Ub4tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findAccuracy(true, predictions):\n",
        "    print('accuracy score: %0.3f' % accuracy_score(true, predictions))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2WBLb6eb7Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainModel(path, no_clusters, clustering_alg, feature_extraction):\n",
        "    images = getFiles(True, path)\n",
        "    print(\"Train images path detected.\")\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    descriptor_list = []\n",
        "    train_labels = np.array([])\n",
        "    image_count = len(images)\n",
        "\n",
        "    for img_path in images:\n",
        "        if (\"airplanes\" in img_path):\n",
        "            class_index = 0\n",
        "        elif (\"cars\" in img_path):\n",
        "            class_index = 1\n",
        "        elif (\"faces\" in img_path):\n",
        "            class_index = 2\n",
        "        elif (\"motorbikes\" in img_path):\n",
        "            class_index = 3\n",
        "\n",
        "        train_labels = np.append(train_labels, class_index)\n",
        "        img = readImage(img_path)\n",
        "        # Feature Extraction\n",
        "        des = getDescriptors(sift, img, feature_extraction)\n",
        "        descriptor_list.append(des)\n",
        "\n",
        "    descriptors = vstackDescriptors(descriptor_list)\n",
        "    print(\"Descriptors vstacked.\")\n",
        "\n",
        "    # Dict Computation\n",
        "    cluster = clusterDescriptors(descriptors, no_clusters, alg=clustering_alg)\n",
        "    print(\"Descriptors clustered with \" + clustering_alg)\n",
        "\n",
        "    im_features = extractFeatures(cluster, descriptor_list, image_count,\n",
        "                                  no_clusters)\n",
        "    print(\"Images features extracted.\")\n",
        "\n",
        "    scale = StandardScaler().fit(im_features)\n",
        "    im_features = scale.transform(im_features)\n",
        "    print(\"Train images normalized.\")\n",
        "\n",
        "    if clustering_alg == 'meanshift':\n",
        "        pass\n",
        "        # labels = cluster.labels_\n",
        "        # cluster_centers = cluster.cluster_centers_\n",
        "        #\n",
        "        # labels_unique = np.unique(labels)\n",
        "        # n_clusters_ = len(labels_unique)\n",
        "        # plotHistogram(im_features, n_clusters_)\n",
        "    else:\n",
        "        plotHistogram(im_features, no_clusters)\n",
        "\n",
        "    print(\"Features histogram plotted.\")\n",
        "    clf = LinearSVC()\n",
        "    clf.fit(im_features, np.array(train_labels))\n",
        "\n",
        "    print(\"SVM fitted.\")\n",
        "    print(\"Training completed.\")\n",
        "\n",
        "    return cluster, scale, clf, im_features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohw1UImmb_SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testModel(path, cluster, scale, svm, im_features, no_clusters,\n",
        "              feature_extraction):\n",
        "    test_images = getFiles(False, path)\n",
        "    print(\"Test images path detected.\")\n",
        "\n",
        "    count = 0\n",
        "    true = []\n",
        "    descriptor_list = []\n",
        "\n",
        "    name_dict = {\n",
        "        \"0\": \"airplanes\",\n",
        "        \"1\": \"cars\",\n",
        "        \"2\": \"faces\",\n",
        "        \"3\": \"motorbikes\",\n",
        "    }\n",
        "\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "\n",
        "    for img_path in test_images:\n",
        "        img = readImage(img_path)\n",
        "        des = getDescriptors(sift, img, feature_extraction)\n",
        "\n",
        "        if (des is not None):\n",
        "            count += 1\n",
        "            descriptor_list.append(des)\n",
        "\n",
        "            if (\"airplanes\" in img_path):\n",
        "                true.append(\"airplanes\")\n",
        "            elif (\"cars\" in img_path):\n",
        "                true.append(\"cars\")\n",
        "            elif (\"faces\" in img_path):\n",
        "                true.append(\"faces\")\n",
        "            elif (\"motorbikes\" in img_path):\n",
        "                true.append(\"motorbikes\")\n",
        "\n",
        "    descriptors = vstackDescriptors(descriptor_list)\n",
        "\n",
        "    test_features = extractFeatures(cluster, descriptor_list, count,\n",
        "                                    no_clusters)\n",
        "\n",
        "    test_features = scale.transform(test_features)\n",
        "\n",
        "    kernel_test = test_features\n",
        "\n",
        "    predictions = [name_dict[str(int(i))] for i in svm.predict(kernel_test)]\n",
        "    print(\"Test images classified.\")\n",
        "\n",
        "    plotConfusions(true, predictions)\n",
        "    print(\"Confusion matrixes plotted.\")\n",
        "\n",
        "    findAccuracy(true, predictions)\n",
        "    print(\"Accuracy calculated.\")\n",
        "    print(\"Execution done.\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OsxuJWdcCeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def execute(train_path, test_path, no_clusters, clustering_alg,\n",
        "            feature_extraction):\n",
        "    cluster, scale, svm, im_features = trainModel(train_path, no_clusters,\n",
        "                                                 clustering_alg, feature_extraction)\n",
        "\n",
        "\n",
        "    # Save the SVM\n",
        "    # joblib.dump((cluster, scale, svm, im_features), (save_file + \".pkl\"),\n",
        "    #             compress=3)\n",
        "    #\n",
        "    # cluster, scale, svm, im_features = joblib.load(save_file + \".pkl\")\n",
        "\n",
        "    testModel(test_path, cluster, scale, svm, im_features, no_clusters, feature_extraction)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhjd2CnUcF9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "30d3b272-c935-4189-b26a-58526910d2e1"
      },
      "source": [
        "    execute('/content/drive/My Drive/bag-of-features/dataset-modified/train', '/content/drive/My Drive/bag-of-features/dataset-modified/test', 50,'kmeans', 'grid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train images path detected.\n",
            "Descriptors vstacked.\n",
            "Descriptors clustered with kmeans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt7IgXK3cxyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}